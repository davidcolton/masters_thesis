% Chapter Template

\chapter{Conclusions} % Main chapter title

\label{chapter6} 

\lhead{Chapter 6. \emph{Conclusions}} 

The application of text mining tools, techniques and processes to the automatic detection of cyberbullying text is still a relatively new research area \cite{xu_fast_2012} \cite{xu_learning_2012}. This dissertation was undertaken in the hope that the findings of this research would add to the subject body of knowledge, and foster further research interest in the area. In this chapter, the objectives of the thesis are reviewed, and the findings of the research are discussed. Consideration is given to the conclusions that can be drawn from the results achieved before making suggestions for possible future work. 

In Chapter \ref{chapter3} it was seen that children and teenagers are using the internet and social media applications to bully each other and that this bullying is known as cyberbullying \cite{dadvar_improved_2012} \cite{kontostathis_detecting_2013}. Cyberbullying was defined as an electronic act, such as images, text or videos, posted to a social media site, that are aggressive in nature against a victim who is typically unable to defend themselves. These postings are made with the sole intent of hurting or embarrassing the victim \cite{nahar_effective_2013} \cite{dadvar_improving_2013}  \cite{dinakar_modeling_2011}. These posts can be sexual or racial in nature, or a direct attack against a persons intelligence or physical appearance \cite{dinakar_common_2012}.

The effects of cyberbullying on its victims can sometimes have tragic consequences. The daily torment and abuse suffered by the victims of cyberbullying can have a dire psychological and emotional toll. The negative affects of posts that contain cyberbullying, of a personal or sensitive nature, can be internalised by children and young adults leading to significant and emotional psychological suffering \cite{dinakar_modeling_2011}. Other effects of cyberbullying can include loneliness, anxiety, low self worth, depression, intra-personal problems, school absence, violent and aggressive behaviour and even suicidal thoughts \cite{xu_fast_2012} \cite{xu_learning_2012}. 

When training a classifier to identify documents of different types, a ``bag of words'' approach is commonly used, sometimes supplemented with other techniques such as examining the role of each party in a bullying incident, or by analysis of the social network graphs of the bully and of the victim. When solely focusing on the documents, or posts, to be classified, the detection of on-line harassment or bullying can consider the content, sentiment and contextual features of the post including such features as N-Grams, foul or curse words and TF-IDF word vectors \cite{yin_detection_2009}. Preprocessing steps can also be applied to the content of the post including stemming, stop word removal and the removal of repeated characters that may have been added by the user that made the post for additional emphasis \cite{dinakar_modeling_2011}. Many classifiers were seen to be used including support vector machines, Naive Bayes and decision trees.

Some common obstacles to the development of classifiers to identify cyberbullying text include anonymity, the lack of suitable datasets, the classification of data and class imbalance. Social media sites that permit the anonymous posting of content are prone to cyberbullying \cite{kontostathis_detecting_2013} \cite{reynolds_using_2011}. When users can post anonymously there is a perception that they are safe and free to bully without fear of discovery \cite{yin_detection_2009}.  It was also suggested that anonymous cyberbullying posts can create a heightened sense of fear in the victim as they are confronted with the unknown, with anonymity giving the bully a feeling of power and control over their victim \cite{nahar_effective_2013}. Anonymous posting also prevents a pattern of abuse being discovered as each anonymous comment on a social media site has to be considered in complete isolation without the possibility of building up a profile of a bully and their social network.

Nearly every major paper reviewed expressed frustration at the lack of a standard labelled dataset that could be used in the research of cyberbullying detection. MySpace, Kongragate and Slashdot datasets provided by Fundaci√≥n Barcelona Media for the CAW 2.0 Workshop \cite{fundacion_barcelona_media_fbm_caw_2009} was used \cite{nahar_effective_2013} \cite{yin_detection_2009} as well as  YouTube video comments \cite{dadvar_improving_2013} \cite{dinakar_modeling_2011}, Twitter tweets \cite{xu_fast_2012} \cite{xu_learning_2012} and data scraped from the www.formspring.me website \cite{kontostathis_detecting_2013} \cite{reynolds_using_2011}. In most cases, the data was manually classified using a simple binary label by the authors, or annotators known to the authors \cite{dadvar_towards_2012} \cite{dadvar_improving_2013} \cite{dinakar_modeling_2011} \cite{yin_detection_2009}, but the Mechanical Turk service offered by Amazon was also used on occasion \cite{kontostathis_detecting_2013} \cite{reynolds_using_2011}.

\section{Summary of research activities}

The primary objective of this thesis was to develop a model, using the Python programming language, that could be used to determine if samples from an unseen dataset should be classified as bullying in nature or classified as not bullying. To meet the objective of this dissertation the following activities were undertaken:

\begin{itemize}

	\item \textbf{Construct a new cyberbullying dataset} \\
	A dataset of over 110,000 samples was created from data scraped from the Ask.fm website. Each sample was in the form of a question of up to 300 characters. A number of preprocessing steps were performed on the samples including converting all characters to lower case, removing non ASCII characters, URLs, punctuation, digits and repeating characters and also replacing some common abbreviations with the complete word. 
	
	\item \textbf{Classify the new cyberbullying dataset} \\
	In order to train a classifier a sample of the complete dataset was manually classified. The criteria used to classify a question as bullying or not was defined resulting in a classified dataset of approximately 9,500 samples of which 1,644 were classified as bullying and 7,899 were classified as not bullying.
	
	\item \textbf{Develop multiple classifiers} \\
	Multiple different classifiers were developed using standard text mining techniques such as n-grams, stop word removal, feature selection and TF-IDF word vectors. These models were developed using Python, the Natural Language Toolkit and the Scikit-Learn suite of libraries.
	
	\item \textbf{Address class imbalance} \\
	Several different techniques were used to address the class imbalance between the positive bullying class and negative not bullying class. Under sampling of the majority negative class, over sampling of the minority positive class and hybrid sampling which used a combination of under and over sampling were all tested. Some cost based testing was also attempted.
	
	\item \textbf{Identify the top classifiers} \\
	All of the models developed were analysed to identify the top classifiers. The models were evaluated against their g-performance, the square root of the positive class recall multiplied by the negative class recall.
	
	\item \textbf{Evaluate top classifiers to determine the best} \\
	Once the top models had been identified, each in turn was further evaluated with previously unseen samples in order to determine which classifier generalises best. This testing, in an attempt to simulate a real life scenario, used an iterative process with previously unseen samples being classified and then appended to the models training data. The model was then regenerated, including these newly classified samples, before additional unseen samples are classified. This process of classify, append and regenerate was repeated multiple times. The results from this testing were then examined in order to determine which classifier could be considered the best.

\end{itemize}

\section{Discussion}

The research question was to determine whether it would be possible to develop a supervised classifier, using Python and standard text mining techniques, that could be used to predict whether an unseen sample should be considered as bullying or not bullying.

The first significant artefact produced as a result of this research is the Ask.fm dataset. The lack of a recognised dataset for use in the research of automated cyberbullying detection is a noted barrier to work in this area. Also, the unsuitability or the unavailability of the datasets used in similar research projects led to the sourcing and construction of a dataset specifically for use in this dissertation from the Ask.fm social networking site. Ask.fm had been successfully used in a similar project \cite{colton:2014}, not to mention that it has recently been in the news headlines as been associated with cyberbullying activity. Over 100,000 sample records, as described in Chapter \ref{chapter4}, were scraped from the Ask.fm site and then a sample set of approximately 9,500 were manually classified. Before classification of the training dataset could begin, the criteria used to identify bullying content was documented and explained. If others wished to build on the work in this thesis, or contest its findings, then the rational behind the decisions made are transparent and understandable. It is very important not to underestimate the consideration given to defining the cyberbullying criteria, the classification effort or the potential future uses of this dataset.

In reviewing and discussing the modelling process, it is worth breaking this large body of work down into smaller parts that can more easily be examined. 

The use of Python and the NLTK and Scikit-Learn packages is a distinguishing feature of this research. Python was chosen for use in this project because of it cross platform support, its ease of use and the ability to quickly see results. Python also has many community supported tools such as NLTK and Scikit-Learn. Python easily met and exceeded all expectations by providing more potential data research opportunities than possible to explore in the limited time available. As was shown, the models developed using both NLTK and Scikit-Learn were extremely feature rich with huge potential for further more detailed research. Especially noteworthy was the speed at which the models were generated and once the model had been created how quickly it could provide a predicted class for an unseen sample. Including some data processing, n-gram generation and file IO activity, the final models using the simulation data, approximately 100,000 samples, were generated in under 5.5 seconds. The classification of the hold back data, including reading the data from file, took only an average of approximately 0.38 seconds for 11,193 samples. This equates to \SI{3.4e-5} seconds for each sample. These are timings from a standard laptop and could be greatly improved upon by the use of faster hardware and also through an optimisation analysis of the python coding to identify bottle necks. Another exciting aspect of the use of Python is the possibility of deploying any potential cyberbullying filtering solutions on mobile devices using Android, iOS or the windows Mobile operating systems. This is explored further in future work.

With 84\% of all sample questions being asked anonymously the use of some of supplemental techniques discovered in the literature review, such as gender analysis, social network evaluation and role determination, were not possible in this research. Other approaches, such as a foul word dictionary, were also discarded in favour or a purely statistical bag of words approach. Word features, TF-IDF word vectors, n-gram combinations and including and removing stop words were all utilised. In line with other research, the data was cleansed before using it for model generation and sample prediction. 

As is common in other related research papers in this field, it was found that there was a positive class imbalance that affected the performance of the learner algorithms utilised. The use of over sampling of the positive minority class, under sampling of the majority negative class and a hybrid sampling approach is not a new concept. It was shown that over sampling can lead to over fitting to the training data resulting in a model that did not generalise to the population. However, over sampling and hybrid sampling were chosen as the most effective sampling techniques ahead of under sampling.

In the literature, there are many suggestions of how best evaluate the performance of a classifier model like those generated in this dissertation. The method chosen was to maximise the recall of both the positive and negative class by using the g-performance measurement. Although a bag of words approach has been used multiple times in previous text mining research, even papers directly related to the cyberbullying issue, none of these, to the knowledge of the author, have attempted an evaluation of the built models as described in Chapter \ref{chapter5} Section \ref{subsection:applying-classifiers}. The availability, and use, of a large dataset of unseen samples that could be used to simulate the evolution of a model and subsequent analysis of the performance of the newly evolved model is novel.


\section{Future Work}

The work performed in this research effort has only scratched the surface of the possibilities offered by the use of Python in the automated detection of cyberbullying content.

When the classifier models were generated, only Naive Bayes and Linear Support Vector learner algorithms were used. There are many other types of supervised and unsupervised learners that were not investigated including the use of ensemble methods. It should also be possible to develop multiple classifiers that each individually specialise on identifying very specific bullying content attributes and then use a majority vote to classify each sample. The confidence of the prediction might also be utilised. 

There is great scope for further investigation into methods to handle the class imbalance problem. For example, identifying a true cost based classifier that is available in Python or, if one don't exist, then the development of a classifier similar to the Weka MetaCost learner. Another avenue of investigation is the use of Synthetic Minority Over-sampling Technique (SMOTE), or the adaptation of this technique for use in a sparse TF-IDF word vector. A weighted approach to hybrid sampling, where the predictive power of each training sample is taken into account, is another possible research opportunity. Rather than randomly choosing samples, the positive and negative samples that are most predictive could be chosen ahead of other more generic samples. Though not directly related to class imbalance the inclusion of a cost for over or under sampling data at the model evaluation stage could prove both novel and enlightening. Further investigation into formalising such an approach is warranted.

Part of speech tagging (POS), is the process of identifying the types of each word in a corpus. For example, to tag all words in the corpus as being a noun, verb, article, or adjective, for example, based on its definition and relationship or adjacency with others in the sentence or paragraph. POS was not used in this research project, but an investigation to determine if its inclusion would positively impact the performance and stability of the models is warranted.

The models developed in this paper were simple binary classifiers where the sample was either bullying or not. It would be interesting to examine if the different types of bullying, for example sexual, racial, threatening, stalking, grooming, could be used to develop a multiclass classifier, maybe utilising Latent Dirichlet allocation for topic identification

The majority of children and teens can now access social media networking sites using mobile devices. Given that Python is available on most of these devices, it would be a challenging software engineering project to develop a tool that integrated the work in this paper with common social networking applications to provide instant filtering, and maybe censorship, to allow parents prevent the delivery of harmful content.

Towards the end of this project, a potential option to allow the inclusion of uni-grams, bi-grams and tri-grams in the same NLTK model was discovered. It would be interesting to repeat this research using n-grams and NLTK in this manner to see if any improvement in the model performance can be achieved. Alternatively investigate if manually generating these n-grams up-front, during initial data exploration, is a viable option.

Finally, this research only used the questions from the Ask.fm dataset. With each question there is an associated answer. Could an analysis of the answers assist in the identification of bullying content. For example, is bullying met with bullying? It would also be revealing to perform sentiment analysis of the answers to determine from the responses given if a user was maybe at risk from self-harm or even having suicidal thoughts.

Appendix \ref{AppendixB} describes a novel approach that could be used to identify the best models without having to evaluate all models individually. The ideas presented, though interesting, need more work in order to determine a more robust and predictable solution. It would, however, be very desirable to develop such a formula for use in any similar future research.

\section{Conclusion}
To conclude, the research question was:

\begin{quote}
The research question of this thesis is whether standard data mining techniques, for example n-grams, stop word removal, feature selection, term frequency inverse document frequency word vectors, can be used to develop a classifier in Python which can be used to predict whether or not unseen samples are bullying in nature.
\end{quote}

From the literature review, modelling and analysis activities performed it was shown that it is possible to develop a cyberbullying classifier using Python and that this dissertation contributes an extensive investigation into the area and is a valuable addition to the subject matter body of knowledge.
