\section{Python, NLTK and Scikit-Learn}
\label{section:2.2}

In this section Python, the Natural Language Toolkit (NLTK) and Scikit-Learn are introduced. Python is the primary tool used to extract, manipulate and process the datasets used in this research. NLTK and Scikit-Learn are the packages that will generate the classifiers used to predict if a sample is either bullying or not bullying.

\subsection{Python}

Python is an open source high-level programming language developed under an OSI approved open source license. Although considered an excellent choice for the user who is only starting to learn how to program, Python offers enough features and functionality to meet the demands of the professional object-oriented programmer as well. It is highly scalable, portable, embeddable and suitable for development projects of all sizes. Another great advantage of Python is a very active community that enthusiastically develops, releases and supports commercial quality libraries, packages, tools and platforms that enhance and extend the core Python capabilities. Two of these, NLTK and Scikit-Learn are extensively used in this research project. 

Python is extensively used at one of the worlds largest internet company, Google, where it used in the Google App Engine and YouTube to name but a few \cite{google_python}. Currently, there are two main versions of Python supported, version 2.7.8 and version 3.4. Instructions how to download, install and configure Python can be found on the Python Language homepage \cite{python}.

\subsection{The Natural Language Toolkit}

The Natural Language Toolkit (NLTK) is a leading platform for building Python programs to work with human language data \cite{nltk}. The NLTK provides a suite of libraries to handle text processing tasks such as corpora parsing, tokenisation, stemming and classification. The NLTK also provides libraries that support part of speech tagging, which converts a sentence into a list of word / tag tuples, and chunk extraction that can be used to extract a short phrase from a sentence that has previously been part of speech tagged. The NLTK also provides easy access to WordNet \cite{miller_wordnet:_1995}, a large lexical database of English nouns, verbs, adjectives and adverbs, and  access to over 50 corpora.

Like Python the NLTK is a free, open source project. It is community driven and is available for Linux, Windows and Mac OS machines. It is currently based on Python version 2.7 but support for version 3 of Python in planned.

\subsection{Scikit-Learn}

Scikit-Learn is a simple and efficient tool for data mining, data analysis and machine learning in Python \cite{scikit-learn}. It utilises other Python libraries such as NumPy, SciPy, and Matplotlib. Like Python and the NLTK, it is open source available under a BSD license. Scikit-Learn includes many supervised learning algorithms including Naive Bayes, Support Vector Machines, Random Forests and Decision Trees as well as many unsupervised learning techniques including clustering and hidden Markov models. As well as supporting cross-validation and providing comprehensive grid search capabilities for parameter optimization, Scikit-Learn also provides extensive model evaluation metrics and scoring options including, for example, precision, recall and accuracy as well easily accessible confusion matrices. Feature extraction including TF-IDF is also supported.

\subsection{Python Resources}

While writing this research thesis the following books provided invaluable support:

\begin{itemize}

	\item Think Python \cite{downey_think_2012}
	\item Python Text Processing with NLTK 2.0 Cookbook \cite{perkins_python_2010}
	\item Learning scikit-learn: Machine Learning in Python \cite{garreta_learning_2013}
	\item Building Machine Learning Systems with Python \cite{Riegel:2013}

\end{itemize} 

\section{MySQL, SPSS and Excel}

MySQL, SPSS and Excel are other tools that were used to a lesser degree throughout the course of this research project.

MySQL is one of the world's most popular open source database. It was used to house the question records from the Ask.fm site before writing the data to disk in NLTK corpora format. SPSS is predictive analytics software from IBM. It includes a lot of tooling to allow the elegant manipulation of textual data including stratified sampling which was made use of in Chapter \ref{chapter4}. Excel is a spreadsheet package from Microsoft that was used to generate all the charts seen in this dissertation.











